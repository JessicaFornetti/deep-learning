{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYWjRH-2Rf5_"
   },
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "olGJje7lF7Pv"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,BatchNormalization,Dropout,UpSampling2D,Reshape,Input\n",
    "from keras.datasets import cifar100\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import save_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL6CT4iERj_G"
   },
   "source": [
    "# Splitting the dataset into Block 1 and Block 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iivYILWs0u5Q"
   },
   "source": [
    "We split the CIFAR 100 dataset into two blocks where each block has 50 classess randomly selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mY8-AXcQJPs-",
    "outputId": "a726234b-66a9-450f-e983-47147f15a68d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-100 dataset\n",
    "(x_all, y_all), (_, _) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# Getting the unique class labels in the dataset\n",
    "classes = np.unique(y_all)\n",
    "\n",
    "# Randomly selecting 50 classes\n",
    "selected_classes = np.random.choice(classes, size=50, replace=False)\n",
    "\n",
    "# Reshaping the labels to 1D array\n",
    "y_train = y_all.reshape(-1)\n",
    "\n",
    "# Splitting the dataset based on the selected classes\n",
    "selected_indices = np.isin(y_train, selected_classes)\n",
    "x_block1 = x_all[selected_indices]\n",
    "y_block1 = y_all[selected_indices]\n",
    "\n",
    "remaining_classes = np.setdiff1d(classes, selected_classes)\n",
    "selected_classes = np.random.choice(remaining_classes, size=50, replace=False)\n",
    "\n",
    "selected_indices = np.isin(y_train, selected_classes)\n",
    "x_block2 = x_all[selected_indices]\n",
    "y_block2 = y_all[selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rN8n2DpIK6WP"
   },
   "outputs": [],
   "source": [
    "# Splitting each block into train and test sets\n",
    "x_block1_train, x_block1_test, y_block1_train, y_block1_test = train_test_split(x_block1, y_block1, test_size=0.2, random_state=42)\n",
    "x_block2_train, x_block2_test, y_block2_train, y_block2_test = train_test_split(x_block2, y_block2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xq_Bh-wbMO8s"
   },
   "outputs": [],
   "source": [
    "# Optionally, we have saved these subsets to disk for later use\n",
    "np.savez_compressed('group1_data.npz', x_train=x_block1_train, y_train=y_block1_train, x_test=x_block1_test, y_test=y_block1_test)\n",
    "np.savez_compressed('group2_data.npz', x_train=x_block2_train, y_train=y_block2_train, x_test=x_block2_test, y_test=y_block2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtUMmqxLRqFX"
   },
   "source": [
    "# Basic Modelling: For Block 1 Images. Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTtkOC3ndgvZ"
   },
   "source": [
    "**[A] Basic CNN Model**\n",
    "\n",
    "1) The Sequential Layer is used to build the model structure.\n",
    "\n",
    "2) The we add 3 Convolutional Layers to the model.\n",
    "\n",
    "   In the 1st Convolutional layer we use 64 kernels , relu activation function and add some padding to capture the important features.\n",
    "\n",
    "   In the 2nd Convolutional layer the number of filters are increased to 128 filters , relu activation function and added some padding to capture the important features.\n",
    "\n",
    "   In the 3rd Convolutional layer the number of filters are increased to 256 filters, relu activation function and added some padding to capture the important features.\n",
    "\n",
    "  3) BatchNormalization is used to normalize each output of the convolutional layer and feed it to the pooling layer.\n",
    "\n",
    "  4) The output of the Pooling layer is flattened. MaxPooling is used which takes the maximum value from each receptive feild of the feature map.\n",
    "\n",
    "  5) Then two fully connected layers are used and one output layer to perform the multi-class classification.\n",
    "\n",
    "  6) In the final layer the softmax activation function is used as it is used for the multi-class classification.\n",
    "\n",
    "     To prevent overfitting dropout layers are added as well as BatchNormalization.\n",
    "\n",
    "        In addition, to increase the accuracy of the model I have tried to increase the complexity of the model by increasing the number of kernels,giving parameters like stride and padding to capture the relevant features in the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgMGkIRKFMEL",
    "outputId": "8ae970a6-e9fd-445f-a8d9-074f8b2f611d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 30, 30, 64)        256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 13, 13, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 4, 4, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               25700     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1054436 (4.02 MB)\n",
      "Trainable params: 1053540 (4.02 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the Basic CNN Model\n",
    "model_cnn = Sequential()\n",
    "\n",
    "model_cnn.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='valid',input_shape=(32,32,3)))\n",
    "model_cnn.add(BatchNormalization())\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model_cnn.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='valid'))\n",
    "model_cnn.add(BatchNormalization())\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model_cnn.add(Conv2D(256,kernel_size=(3,3),activation='relu',padding='valid'))\n",
    "model_cnn.add(BatchNormalization())\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model_cnn.add(Flatten())\n",
    "\n",
    "model_cnn.add(Dense(512,activation='relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(256,activation='relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(100,activation='softmax'))\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trJJWiEuFL-H"
   },
   "outputs": [],
   "source": [
    "model_cnn.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR8lWyMtggDg"
   },
   "source": [
    "Callbacks was used to improve the performance and efficiency of neural network training by preventing overfitting and fine-tuning the learning rate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCk9ct70FL5a"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),  # Early stopping to prevent overfitting\n",
    "    ReduceLROnPlateau(factor=0.2, patience=3, min_lr=1e-6)  # Reduce learning rate on plateau\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHN8n_ivFL10",
    "outputId": "1944f975-61ea-4dad-e7c2-0429cb656b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "625/625 [==============================] - 122s 196ms/step - loss: 3.2040 - accuracy: 0.1817 - val_loss: 2.8648 - val_accuracy: 0.2634 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "625/625 [==============================] - 123s 197ms/step - loss: 3.0057 - accuracy: 0.2215 - val_loss: 2.9420 - val_accuracy: 0.2452 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "625/625 [==============================] - 118s 188ms/step - loss: 2.8419 - accuracy: 0.2587 - val_loss: 2.8079 - val_accuracy: 0.2612 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "625/625 [==============================] - 117s 187ms/step - loss: 2.6974 - accuracy: 0.2923 - val_loss: 2.4951 - val_accuracy: 0.3382 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "625/625 [==============================] - 122s 196ms/step - loss: 2.5675 - accuracy: 0.3180 - val_loss: 2.5892 - val_accuracy: 0.3156 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "625/625 [==============================] - 119s 190ms/step - loss: 2.4524 - accuracy: 0.3476 - val_loss: 2.6150 - val_accuracy: 0.3174 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "625/625 [==============================] - 116s 186ms/step - loss: 2.3277 - accuracy: 0.3733 - val_loss: 2.9615 - val_accuracy: 0.2684 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 2.0386 - accuracy: 0.4339 - val_loss: 2.0088 - val_accuracy: 0.4568 - lr: 2.0000e-04\n",
      "Epoch 9/40\n",
      "625/625 [==============================] - 120s 193ms/step - loss: 1.8848 - accuracy: 0.4711 - val_loss: 1.9392 - val_accuracy: 0.4740 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 1.7820 - accuracy: 0.4992 - val_loss: 1.9313 - val_accuracy: 0.4740 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "625/625 [==============================] - 121s 194ms/step - loss: 1.7255 - accuracy: 0.5060 - val_loss: 1.9091 - val_accuracy: 0.4880 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "625/625 [==============================] - 116s 185ms/step - loss: 1.6415 - accuracy: 0.5272 - val_loss: 1.9647 - val_accuracy: 0.4762 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "625/625 [==============================] - 119s 190ms/step - loss: 1.5731 - accuracy: 0.5449 - val_loss: 1.8973 - val_accuracy: 0.4938 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 1.5071 - accuracy: 0.5600 - val_loss: 1.8752 - val_accuracy: 0.4952 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "625/625 [==============================] - 115s 183ms/step - loss: 1.4444 - accuracy: 0.5741 - val_loss: 1.9079 - val_accuracy: 0.4890 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "625/625 [==============================] - 120s 192ms/step - loss: 1.4011 - accuracy: 0.5851 - val_loss: 1.8840 - val_accuracy: 0.5018 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "625/625 [==============================] - 134s 215ms/step - loss: 1.3326 - accuracy: 0.5993 - val_loss: 1.8966 - val_accuracy: 0.5018 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "625/625 [==============================] - 156s 250ms/step - loss: 1.2345 - accuracy: 0.6264 - val_loss: 1.8700 - val_accuracy: 0.5102 - lr: 4.0000e-05\n",
      "Epoch 19/40\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 1.2048 - accuracy: 0.6309 - val_loss: 1.8703 - val_accuracy: 0.5116 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "625/625 [==============================] - 118s 189ms/step - loss: 1.1806 - accuracy: 0.6380 - val_loss: 1.8743 - val_accuracy: 0.5110 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "625/625 [==============================] - 112s 179ms/step - loss: 1.1664 - accuracy: 0.6401 - val_loss: 1.8879 - val_accuracy: 0.5106 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "625/625 [==============================] - 111s 178ms/step - loss: 1.1445 - accuracy: 0.6498 - val_loss: 1.8791 - val_accuracy: 0.5130 - lr: 8.0000e-06\n",
      "Epoch 23/40\n",
      "625/625 [==============================] - 113s 181ms/step - loss: 1.1432 - accuracy: 0.6480 - val_loss: 1.8806 - val_accuracy: 0.5138 - lr: 8.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history_cnn = model_cnn.fit(x_block1_train,y_block1_train,epochs=40,validation_data=(x_block1_test,y_block1_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BGuZkdDSUJu"
   },
   "source": [
    "**[B] Testing with the 'tanh' Activation Function in the Hidden Layers.**\n",
    "\n",
    "1) The activation function is changed to see how that affects the model's performance.\n",
    "\n",
    "2) Instead of relu, the tanh activation function is used within the hidden layers.\n",
    "\n",
    "3) However we can see that the accuracy decreases when we use the tanh function in the hidden layers compared to the other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6PcP6TBSZyR",
    "outputId": "45b3c4aa-c92c-4ad0-f49e-d5c99d059549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 30, 30, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 15, 15, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 13, 13, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 6, 6, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 4, 4, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 2, 2, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               25700     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1054436 (4.02 MB)\n",
      "Trainable params: 1053540 (4.02 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tanh = Sequential()\n",
    "\n",
    "model_tanh.add(Conv2D(64,kernel_size=(3,3),activation='tanh',padding='valid',input_shape=(32,32,3)))\n",
    "model_tanh.add(BatchNormalization())\n",
    "model_tanh.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model_tanh.add(Conv2D(128,kernel_size=(3,3),activation='tanh',padding='valid'))\n",
    "model_tanh.add(BatchNormalization())\n",
    "model_tanh.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model_tanh.add(Conv2D(256,kernel_size=(3,3),activation='tanh',padding='valid'))\n",
    "model_tanh.add(BatchNormalization())\n",
    "model_tanh.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model_tanh.add(Flatten())\n",
    "\n",
    "model_tanh.add(Dense(512,activation='tanh'))\n",
    "model_tanh.add(Dropout(0.5))\n",
    "model_tanh.add(Dense(256,activation='tanh'))\n",
    "model_tanh.add(Dropout(0.5))\n",
    "model_tanh.add(Dense(100,activation='softmax'))\n",
    "\n",
    "model_tanh.summary()\n",
    "\n",
    "model_tanh.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRZQ3TcpUm4q",
    "outputId": "8110cb85-5124-4b6b-dec3-446b0044217b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "625/625 [==============================] - 166s 259ms/step - loss: 3.9863 - accuracy: 0.0693 - val_loss: 4.7414 - val_accuracy: 0.0488 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "625/625 [==============================] - 134s 215ms/step - loss: 3.6288 - accuracy: 0.1086 - val_loss: 4.4122 - val_accuracy: 0.0594 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "625/625 [==============================] - 129s 207ms/step - loss: 3.4513 - accuracy: 0.1287 - val_loss: 4.1860 - val_accuracy: 0.0456 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "625/625 [==============================] - 121s 193ms/step - loss: 3.3294 - accuracy: 0.1478 - val_loss: 3.3939 - val_accuracy: 0.1402 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "625/625 [==============================] - 120s 192ms/step - loss: 3.2137 - accuracy: 0.1717 - val_loss: 3.2071 - val_accuracy: 0.1738 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "625/625 [==============================] - 120s 192ms/step - loss: 3.1868 - accuracy: 0.1796 - val_loss: 3.2751 - val_accuracy: 0.1744 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "625/625 [==============================] - 121s 194ms/step - loss: 3.1472 - accuracy: 0.1843 - val_loss: 2.9733 - val_accuracy: 0.2294 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "625/625 [==============================] - 120s 191ms/step - loss: 3.0709 - accuracy: 0.2051 - val_loss: 3.3037 - val_accuracy: 0.1834 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "625/625 [==============================] - 121s 194ms/step - loss: 3.0217 - accuracy: 0.2125 - val_loss: 3.1567 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "625/625 [==============================] - 132s 212ms/step - loss: 3.0045 - accuracy: 0.2198 - val_loss: 2.8521 - val_accuracy: 0.2438 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "625/625 [==============================] - 121s 194ms/step - loss: 3.0011 - accuracy: 0.2160 - val_loss: 3.7634 - val_accuracy: 0.1164 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "625/625 [==============================] - 123s 197ms/step - loss: 3.0290 - accuracy: 0.2113 - val_loss: 3.1555 - val_accuracy: 0.1926 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "625/625 [==============================] - 120s 192ms/step - loss: 2.9422 - accuracy: 0.2299 - val_loss: 3.1678 - val_accuracy: 0.1814 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 2.7959 - accuracy: 0.2646 - val_loss: 2.6211 - val_accuracy: 0.3010 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "625/625 [==============================] - 127s 204ms/step - loss: 2.7136 - accuracy: 0.2760 - val_loss: 2.5331 - val_accuracy: 0.3154 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "625/625 [==============================] - 124s 198ms/step - loss: 2.6596 - accuracy: 0.2885 - val_loss: 2.5368 - val_accuracy: 0.3198 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "625/625 [==============================] - 124s 199ms/step - loss: 2.6139 - accuracy: 0.3054 - val_loss: 2.4935 - val_accuracy: 0.3256 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "625/625 [==============================] - 121s 193ms/step - loss: 2.5744 - accuracy: 0.3108 - val_loss: 2.5060 - val_accuracy: 0.3276 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "625/625 [==============================] - 121s 194ms/step - loss: 2.5473 - accuracy: 0.3183 - val_loss: 2.4778 - val_accuracy: 0.3328 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "625/625 [==============================] - 121s 193ms/step - loss: 2.5109 - accuracy: 0.3250 - val_loss: 2.4482 - val_accuracy: 0.3408 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 2.4888 - accuracy: 0.3312 - val_loss: 2.4765 - val_accuracy: 0.3370 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "625/625 [==============================] - 124s 199ms/step - loss: 2.4592 - accuracy: 0.3385 - val_loss: 2.5060 - val_accuracy: 0.3204 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "625/625 [==============================] - 126s 201ms/step - loss: 2.4309 - accuracy: 0.3444 - val_loss: 2.4876 - val_accuracy: 0.3348 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "625/625 [==============================] - 123s 197ms/step - loss: 2.3681 - accuracy: 0.3575 - val_loss: 2.4081 - val_accuracy: 0.3506 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "625/625 [==============================] - 124s 198ms/step - loss: 2.3437 - accuracy: 0.3672 - val_loss: 2.3993 - val_accuracy: 0.3554 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "625/625 [==============================] - 115s 183ms/step - loss: 2.3342 - accuracy: 0.3655 - val_loss: 2.4023 - val_accuracy: 0.3528 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 2.3309 - accuracy: 0.3665 - val_loss: 2.3981 - val_accuracy: 0.3536 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "625/625 [==============================] - 117s 187ms/step - loss: 2.3146 - accuracy: 0.3679 - val_loss: 2.3927 - val_accuracy: 0.3482 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "625/625 [==============================] - 121s 194ms/step - loss: 2.3063 - accuracy: 0.3733 - val_loss: 2.3966 - val_accuracy: 0.3558 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "625/625 [==============================] - 118s 188ms/step - loss: 2.2984 - accuracy: 0.3711 - val_loss: 2.3934 - val_accuracy: 0.3542 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "625/625 [==============================] - 116s 186ms/step - loss: 2.2822 - accuracy: 0.3751 - val_loss: 2.3852 - val_accuracy: 0.3520 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "625/625 [==============================] - 113s 181ms/step - loss: 2.2814 - accuracy: 0.3732 - val_loss: 2.3832 - val_accuracy: 0.3568 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "625/625 [==============================] - 118s 189ms/step - loss: 2.2683 - accuracy: 0.3811 - val_loss: 2.3883 - val_accuracy: 0.3536 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "625/625 [==============================] - 120s 192ms/step - loss: 2.2533 - accuracy: 0.3867 - val_loss: 2.3821 - val_accuracy: 0.3582 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "625/625 [==============================] - 117s 187ms/step - loss: 2.2462 - accuracy: 0.3854 - val_loss: 2.3815 - val_accuracy: 0.3560 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "625/625 [==============================] - 118s 188ms/step - loss: 2.2281 - accuracy: 0.3866 - val_loss: 2.3838 - val_accuracy: 0.3586 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "625/625 [==============================] - 113s 181ms/step - loss: 2.2212 - accuracy: 0.3929 - val_loss: 2.3819 - val_accuracy: 0.3584 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "625/625 [==============================] - 113s 180ms/step - loss: 2.2174 - accuracy: 0.3956 - val_loss: 2.3872 - val_accuracy: 0.3560 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "625/625 [==============================] - 117s 187ms/step - loss: 2.2076 - accuracy: 0.3971 - val_loss: 2.3783 - val_accuracy: 0.3596 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "625/625 [==============================] - 112s 179ms/step - loss: 2.2066 - accuracy: 0.3952 - val_loss: 2.3801 - val_accuracy: 0.3572 - lr: 8.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7dbbcca9e800>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tanh.fit(x_block1_train,y_block1_train,epochs=40,validation_data=(x_block1_test,y_block1_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iJ_t97aWElb"
   },
   "source": [
    "**[C] Testing with the Logstic(Sigmoid) Activation function in the Final Layer.**\n",
    "\n",
    "Here the activation function in the final layer is changed to use the sigmoid activation function instead.\n",
    "\n",
    "However we can see that the model is overfitting as it gives poor validation accuracy.\n",
    "\n",
    "Compared to the basic CNN model both have similar validation accuracy, however this model seems to overfit a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6rbjPc1VYJc",
    "outputId": "43ac3e7b-6f42-41e0-d008-e2c4d5ae57f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_84 (Conv2D)          (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 30, 30, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPooli  (None, 15, 15, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 13, 13, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPooli  (None, 6, 6, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  (None, 4, 4, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPooli  (None, 2, 2, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               25700     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1054436 (4.02 MB)\n",
      "Trainable params: 1053540 (4.02 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = Sequential()\n",
    "\n",
    "model_sigmoid.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='valid',input_shape=(32,32,3)))\n",
    "model_sigmoid.add(BatchNormalization())\n",
    "model_sigmoid.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model_sigmoid.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='valid'))\n",
    "model_sigmoid.add(BatchNormalization())\n",
    "model_sigmoid.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model_sigmoid.add(Conv2D(256,kernel_size=(3,3),activation='relu',padding='valid'))\n",
    "model_sigmoid.add(BatchNormalization())\n",
    "model_sigmoid.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model_sigmoid.add(Flatten())\n",
    "\n",
    "model_sigmoid.add(Dense(512,activation='relu'))\n",
    "model_sigmoid.add(Dropout(0.5))\n",
    "model_sigmoid.add(Dense(256,activation='relu'))\n",
    "model_sigmoid.add(Dropout(0.5))\n",
    "model_sigmoid.add(Dense(100,activation='sigmoid'))\n",
    "\n",
    "model_sigmoid.summary()\n",
    "\n",
    "model_sigmoid.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gI2vn-N8VcTk",
    "outputId": "f20ecea1-4cbd-4b8e-91a6-49677bb29546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "625/625 [==============================] - 118s 186ms/step - loss: 3.8441 - accuracy: 0.0945 - val_loss: 3.1268 - val_accuracy: 0.2036 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "625/625 [==============================] - 110s 175ms/step - loss: 3.2849 - accuracy: 0.1675 - val_loss: 3.0186 - val_accuracy: 0.2146 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "625/625 [==============================] - 115s 184ms/step - loss: 3.0565 - accuracy: 0.2156 - val_loss: 2.8757 - val_accuracy: 0.2472 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "625/625 [==============================] - 118s 189ms/step - loss: 2.8873 - accuracy: 0.2482 - val_loss: 2.6249 - val_accuracy: 0.3090 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "625/625 [==============================] - 109s 175ms/step - loss: 2.7572 - accuracy: 0.2801 - val_loss: 2.4807 - val_accuracy: 0.3414 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "625/625 [==============================] - 117s 187ms/step - loss: 2.6087 - accuracy: 0.3085 - val_loss: 2.6206 - val_accuracy: 0.3124 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "625/625 [==============================] - 120s 192ms/step - loss: 2.4892 - accuracy: 0.3382 - val_loss: 2.3914 - val_accuracy: 0.3628 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "625/625 [==============================] - 113s 180ms/step - loss: 2.3808 - accuracy: 0.3627 - val_loss: 2.4481 - val_accuracy: 0.3542 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "625/625 [==============================] - 113s 181ms/step - loss: 2.2818 - accuracy: 0.3837 - val_loss: 2.4658 - val_accuracy: 0.3522 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "625/625 [==============================] - 116s 185ms/step - loss: 2.1709 - accuracy: 0.4063 - val_loss: 2.2602 - val_accuracy: 0.4012 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "625/625 [==============================] - 110s 177ms/step - loss: 2.0641 - accuracy: 0.4341 - val_loss: 2.2278 - val_accuracy: 0.4016 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "625/625 [==============================] - 112s 179ms/step - loss: 1.9499 - accuracy: 0.4581 - val_loss: 2.1918 - val_accuracy: 0.4142 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "625/625 [==============================] - 115s 184ms/step - loss: 1.8635 - accuracy: 0.4861 - val_loss: 2.1570 - val_accuracy: 0.4278 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "625/625 [==============================] - 116s 186ms/step - loss: 1.7686 - accuracy: 0.5058 - val_loss: 1.9642 - val_accuracy: 0.4738 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "625/625 [==============================] - 116s 186ms/step - loss: 1.6848 - accuracy: 0.5245 - val_loss: 2.1271 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "625/625 [==============================] - 113s 181ms/step - loss: 1.5951 - accuracy: 0.5472 - val_loss: 2.0510 - val_accuracy: 0.4510 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "625/625 [==============================] - 111s 177ms/step - loss: 1.5127 - accuracy: 0.5707 - val_loss: 2.6476 - val_accuracy: 0.3630 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "625/625 [==============================] - 115s 185ms/step - loss: 1.2682 - accuracy: 0.6297 - val_loss: 1.8834 - val_accuracy: 0.5060 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "625/625 [==============================] - 117s 187ms/step - loss: 1.1402 - accuracy: 0.6581 - val_loss: 1.8623 - val_accuracy: 0.5072 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "625/625 [==============================] - 112s 180ms/step - loss: 1.0712 - accuracy: 0.6797 - val_loss: 1.9133 - val_accuracy: 0.5060 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "625/625 [==============================] - 119s 190ms/step - loss: 1.0117 - accuracy: 0.6890 - val_loss: 1.9037 - val_accuracy: 0.5162 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "625/625 [==============================] - 118s 189ms/step - loss: 0.9612 - accuracy: 0.7088 - val_loss: 1.9111 - val_accuracy: 0.5222 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "625/625 [==============================] - 117s 187ms/step - loss: 0.9002 - accuracy: 0.7189 - val_loss: 1.9089 - val_accuracy: 0.5220 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "625/625 [==============================] - 116s 186ms/step - loss: 0.8864 - accuracy: 0.7201 - val_loss: 1.9168 - val_accuracy: 0.5198 - lr: 4.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7dbbcc7cbc70>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sigmoid.fit(x_block1_train,y_block1_train,epochs=40,validation_data=(x_block1_test,y_block1_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tIAyEfdGmVG"
   },
   "source": [
    "**[D] Adding Skip connections in the Model.**\n",
    "\n",
    "Here skip connection layers are added to our basic CNN model.\n",
    "\n",
    "Skip connections are added to the second and third convolutional blocks to preserve spatial information and aid in gradient propagation during training.\n",
    "\n",
    "Then the skip connections are concatenated with the output of the previous layers, and the concatenated output is passed through additional fully connected layers and finally an output layer with softmax activation for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sWp3qzAxR0V",
    "outputId": "aa0861dc-a1d6-4441-9cb4-dbb4211e118d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " conv2d_87_input (InputLaye  [(None, 32, 32, 3)]          0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)          (None, 30, 30, 64)           1792      ['conv2d_87_input[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, 30, 30, 64)           256       ['conv2d_87[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_42 (MaxPooli  (None, 15, 15, 64)           0         ['batch_normalization_41[0][0]\n",
      " ng2D)                                                              ']                            \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)          (None, 13, 13, 128)          73856     ['max_pooling2d_42[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (None, 13, 13, 128)          512       ['conv2d_88[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_43 (MaxPooli  (None, 6, 6, 128)            0         ['batch_normalization_42[0][0]\n",
      " ng2D)                                                              ']                            \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)          (None, 4, 4, 256)            295168    ['max_pooling2d_43[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (None, 4, 4, 256)            1024      ['conv2d_89[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_44 (MaxPooli  (None, 2, 2, 256)            0         ['batch_normalization_43[0][0]\n",
      " ng2D)                                                              ']                            \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 1024)                 0         ['max_pooling2d_44[0][0]']    \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 512)                  524800    ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 4608)                 0         ['max_pooling2d_43[0][0]']    \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)         (None, 1024)                 0         ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 6144)                 0         ['dense_12[0][0]',            \n",
      "                                                                     'flatten_5[0][0]',           \n",
      "                                                                     'flatten_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 256)                  1573120   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 256)                  0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 100)                  25700     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2496228 (9.52 MB)\n",
      "Trainable params: 2495332 (9.52 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, Add, Concatenate\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional block\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='valid', input_shape=(32,32,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "# Second convolutional block with skip connection\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "# Third convolutional block with skip connection\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Skip connection from the second convolutional block\n",
    "skip1 = model.layers[5].output  # Get the output of the second convolutional block\n",
    "skip2 = model.layers[9].output  # Get the output of the third convolutional block\n",
    "\n",
    "# Flatten the skip connections to match the output shape of the previous layers\n",
    "skip1_flatten = Flatten()(skip1)\n",
    "skip2_flatten = Flatten()(skip2)\n",
    "\n",
    "# Concatenate skip connections with the output of the previous layers\n",
    "concatenated_output = Concatenate()([model.layers[-1].output, skip1_flatten, skip2_flatten])\n",
    "\n",
    "# Fully connected layers\n",
    "concatenated_output = Dense(256, activation='relu')(concatenated_output)\n",
    "concatenated_output = Dropout(0.5)(concatenated_output)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(100, activation='softmax')(concatenated_output)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrGx_z0jTmPt",
    "outputId": "d1db52b1-56e4-4dee-c56a-2afeca865b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_82\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " conv2d_199_input (InputLay  [(None, 32, 32, 3)]          0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)         (None, 30, 30, 64)           1792      ['conv2d_199_input[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_222 (B  (None, 30, 30, 64)           256       ['conv2d_199[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_179 (MaxPool  (None, 15, 15, 64)           0         ['batch_normalization_222[0][0\n",
      " ing2D)                                                             ]']                           \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)         (None, 13, 13, 128)          73856     ['max_pooling2d_179[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_223 (B  (None, 13, 13, 128)          512       ['conv2d_200[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_180 (MaxPool  (None, 6, 6, 128)            0         ['batch_normalization_223[0][0\n",
      " ing2D)                                                             ]']                           \n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)         (None, 4, 4, 256)            295168    ['max_pooling2d_180[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_224 (B  (None, 4, 4, 256)            1024      ['conv2d_201[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_181 (MaxPool  (None, 2, 2, 256)            0         ['batch_normalization_224[0][0\n",
      " ing2D)                                                             ]']                           \n",
      "                                                                                                  \n",
      " flatten_64 (Flatten)        (None, 1024)                 0         ['max_pooling2d_181[0][0]']   \n",
      "                                                                                                  \n",
      " dense_168 (Dense)           (None, 512)                  524800    ['flatten_64[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_65 (Flatten)        (None, 4608)                 0         ['max_pooling2d_180[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_66 (Flatten)        (None, 1024)                 0         ['flatten_64[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 6144)                 0         ['dense_168[0][0]',           \n",
      " )                                                                   'flatten_65[0][0]',          \n",
      "                                                                     'flatten_66[0][0]']          \n",
      "                                                                                                  \n",
      " dense_169 (Dense)           (None, 256)                  1573120   ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)        (None, 256)                  0         ['dense_169[0][0]']           \n",
      "                                                                                                  \n",
      " dense_170 (Dense)           (None, 100)                  25700     ['dropout_26[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2496228 (9.52 MB)\n",
      "Trainable params: 2495332 (9.52 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RyT3wqpbTtU5"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l02W5sbs7hk_"
   },
   "source": [
    "When comparing the results to the previous models, it has similar validation accuracy along with similar traning accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-Dw04-rUS0c",
    "outputId": "eb908c82-bbca-4544-e32e-def00236d3a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 203s 324ms/step - loss: 3.8948 - accuracy: 0.1010 - val_loss: 3.6283 - val_accuracy: 0.0976 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "625/625 [==============================] - 210s 336ms/step - loss: 3.2384 - accuracy: 0.1705 - val_loss: 3.3571 - val_accuracy: 0.1804 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "625/625 [==============================] - 201s 322ms/step - loss: 3.0071 - accuracy: 0.2169 - val_loss: 2.7470 - val_accuracy: 0.2754 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "625/625 [==============================] - 199s 319ms/step - loss: 2.7956 - accuracy: 0.2526 - val_loss: 2.6749 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "625/625 [==============================] - 208s 333ms/step - loss: 2.6384 - accuracy: 0.2822 - val_loss: 2.5709 - val_accuracy: 0.3196 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "625/625 [==============================] - 197s 316ms/step - loss: 2.4951 - accuracy: 0.3108 - val_loss: 2.4904 - val_accuracy: 0.3242 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "625/625 [==============================] - 195s 313ms/step - loss: 2.3309 - accuracy: 0.3442 - val_loss: 2.4418 - val_accuracy: 0.3540 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "625/625 [==============================] - 209s 335ms/step - loss: 2.1981 - accuracy: 0.3706 - val_loss: 2.6119 - val_accuracy: 0.3258 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "625/625 [==============================] - 207s 331ms/step - loss: 2.0671 - accuracy: 0.4045 - val_loss: 2.4227 - val_accuracy: 0.3706 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "625/625 [==============================] - 202s 323ms/step - loss: 1.9426 - accuracy: 0.4321 - val_loss: 2.3975 - val_accuracy: 0.3896 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "625/625 [==============================] - 211s 337ms/step - loss: 1.8125 - accuracy: 0.4608 - val_loss: 2.1248 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "625/625 [==============================] - 195s 312ms/step - loss: 1.6886 - accuracy: 0.4917 - val_loss: 2.2501 - val_accuracy: 0.4078 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "625/625 [==============================] - 197s 316ms/step - loss: 1.6123 - accuracy: 0.5090 - val_loss: 2.1920 - val_accuracy: 0.4414 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "625/625 [==============================] - 198s 317ms/step - loss: 1.4948 - accuracy: 0.5407 - val_loss: 2.1661 - val_accuracy: 0.4350 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "625/625 [==============================] - 198s 317ms/step - loss: 1.1839 - accuracy: 0.6202 - val_loss: 1.9988 - val_accuracy: 0.4894 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "625/625 [==============================] - 195s 313ms/step - loss: 1.0528 - accuracy: 0.6528 - val_loss: 2.0483 - val_accuracy: 0.4946 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "625/625 [==============================] - 195s 313ms/step - loss: 0.9882 - accuracy: 0.6743 - val_loss: 2.0995 - val_accuracy: 0.5018 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "625/625 [==============================] - 207s 331ms/step - loss: 0.9048 - accuracy: 0.6971 - val_loss: 2.2044 - val_accuracy: 0.4950 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "625/625 [==============================] - 193s 309ms/step - loss: 0.8256 - accuracy: 0.7172 - val_loss: 2.1501 - val_accuracy: 0.5056 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "625/625 [==============================] - 193s 308ms/step - loss: 0.8053 - accuracy: 0.7256 - val_loss: 2.1863 - val_accuracy: 0.5052 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_block1_train,y_block1_train,epochs=40,validation_data=(x_block1_test,y_block1_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OR2bAoIJDQr"
   },
   "source": [
    "#### Saving the best model for CNN.\n",
    "We save the CNN model which has skip connection layers in it, as it seems to overfit less and gives reasonable accuracy as compared to the other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOZdmYFeJGq7",
    "outputId": "ff1e7131-3faf-4c7f-df89-7d5f1c12cd80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-151-95e3b0cb683e>:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model,'best_cnn_model.h5')\n"
     ]
    }
   ],
   "source": [
    "save_model(model,'best_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eq9gl_Ax75-j"
   },
   "source": [
    "We plot the graphs for better visvualization of the accuracy values and the losses for the traning and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "T_FYaX1VWYfb",
    "outputId": "fd2e9519-4736-48e8-a115-113b230b0e45"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'],color='red',label='train')\n",
    "plt.plot(history.history['val_accuracy'],color='blue',label='val')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "zIk4XyuaefCy",
    "outputId": "2b0c4f9b-3694-4be2-8ba1-0306f295ab50"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'],color='red',label='train')\n",
    "plt.plot(history.history['val_loss'],color='blue',label='val')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7REaDs4i7I3-"
   },
   "source": [
    "# Autoencoders Modelling : For Block 1 Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ez3l5_sltee"
   },
   "source": [
    "The autoencoder model described below is created:\n",
    "\n",
    "1) Encoder (CNN):\n",
    "In the 1st chunck the input shape for the encoder is defined.\n",
    "Then three convolutional layers are added with increasing number of filters (16, 32, and 64 respectively), each followed by LeakyReLU activation functions. These layers help to extract features from the input image.\n",
    "After three max-pooling layers are added to reduce the spatial dimensions of the feature maps, helping in retaining the most important features.\n",
    "The output of the last max-pooling layer represents the encoded (compressed) representation of the input image.\n",
    "\n",
    "2) Flatten Layer:\n",
    "It flattens the output of the encoder into a 1D vector, preparing it for the classifier.\n",
    "\n",
    "3) Classifier:\n",
    "Two fully connected layers (128 neurons followed by 64 neurons) with ReLU activation functions are used, followed by a final output layer with softmax activation. This part of the model classifies the encoded features into one of the predefined classes (100 in this case).\n",
    "\n",
    "4) Decoder:\n",
    "Three upsampling layers are used which increase the spatial dimensions of the encoded representation to match the original input image size.\n",
    "Two transposed convolutional layers with decreasing number of filters (64 and 32 respectively), each followed by ReLU activation functions and batch normalization are then used. These layers help in reconstructing the original input image.\n",
    "The final layer with sigmoid activation then reconstructs the color channels of the input image.\n",
    "\n",
    " 5) Autoencoder Model\n",
    " The autoencoder model is defined with the input and output layers. It is then compiled using the Adam optimizer and mean squared error loss, suitable for image reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Ni_SNlZuyhY",
    "outputId": "bac2527b-99c7-4bc2-8888-5dc9fad599d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_47 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " model_44 (Functional)       (None, 8, 8, 32)          20640     \n",
      "                                                                 \n",
      " model_45 (Functional)       (None, 32, 32, 3)         29859     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50499 (197.26 KB)\n",
      "Trainable params: 50115 (195.76 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "157/157 [==============================] - 125s 780ms/step - loss: 20060.8281 - accuracy: 0.4858 - val_loss: 20319.3047 - val_accuracy: 0.4562\n",
      "Epoch 2/15\n",
      "157/157 [==============================] - 122s 776ms/step - loss: 20046.1367 - accuracy: 0.5083 - val_loss: 20319.1719 - val_accuracy: 0.5216\n",
      "Epoch 3/15\n",
      "157/157 [==============================] - 125s 796ms/step - loss: 20045.5176 - accuracy: 0.5145 - val_loss: 20319.1328 - val_accuracy: 0.5110\n",
      "Epoch 4/15\n",
      "157/157 [==============================] - 122s 778ms/step - loss: 20045.5215 - accuracy: 0.4754 - val_loss: 20319.2715 - val_accuracy: 0.4164\n",
      "Epoch 5/15\n",
      "157/157 [==============================] - 124s 787ms/step - loss: 20045.3887 - accuracy: 0.4625 - val_loss: 20319.1113 - val_accuracy: 0.4983\n",
      "Epoch 6/15\n",
      "157/157 [==============================] - 122s 776ms/step - loss: 20045.3047 - accuracy: 0.4896 - val_loss: 20319.0996 - val_accuracy: 0.5111\n",
      "Epoch 7/15\n",
      "157/157 [==============================] - 124s 788ms/step - loss: 20045.2969 - accuracy: 0.4955 - val_loss: 20319.0977 - val_accuracy: 0.4798\n",
      "Epoch 8/15\n",
      "157/157 [==============================] - 124s 790ms/step - loss: 20045.4043 - accuracy: 0.4490 - val_loss: 20319.1445 - val_accuracy: 0.5495\n",
      "Epoch 9/15\n",
      "157/157 [==============================] - 123s 782ms/step - loss: 20045.2891 - accuracy: 0.4534 - val_loss: 20319.0938 - val_accuracy: 0.4715\n",
      "Epoch 10/15\n",
      "157/157 [==============================] - 121s 771ms/step - loss: 20045.2812 - accuracy: 0.4466 - val_loss: 20319.0938 - val_accuracy: 0.4529\n",
      "Epoch 11/15\n",
      "157/157 [==============================] - 122s 778ms/step - loss: 20045.2871 - accuracy: 0.4498 - val_loss: 20319.0938 - val_accuracy: 0.4630\n",
      "Epoch 12/15\n",
      "157/157 [==============================] - 124s 787ms/step - loss: 20045.2832 - accuracy: 0.4554 - val_loss: 20319.0938 - val_accuracy: 0.4651\n",
      "Epoch 13/15\n",
      "157/157 [==============================] - 123s 786ms/step - loss: 20045.3066 - accuracy: 0.4565 - val_loss: 20319.0957 - val_accuracy: 0.4236\n",
      "Epoch 14/15\n",
      "157/157 [==============================] - 120s 762ms/step - loss: 20045.2793 - accuracy: 0.4643 - val_loss: 20319.0938 - val_accuracy: 0.4560\n",
      "Epoch 15/15\n",
      "157/157 [==============================] - 119s 756ms/step - loss: 20045.2754 - accuracy: 0.4671 - val_loss: 20319.0898 - val_accuracy: 0.4685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x790d61a84eb0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (32, 32, 3)  # Assuming CIFAR-100 images\n",
    "\n",
    "# Define the encoder part of the autoencoder\n",
    "def build_encoder(input_shape):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    return Model(input_img, encoded)\n",
    "\n",
    "# Define the decoder part of the autoencoder\n",
    "def build_decoder(encoded_shape):\n",
    "    input_encoded = Input(shape=encoded_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_encoded)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    return Model(input_encoded, decoded)\n",
    "\n",
    "# Build the encoder and decoder models\n",
    "encoder = build_encoder(input_shape)\n",
    "decoder = build_decoder(encoder.output_shape[1:])\n",
    "\n",
    "# Build the autoencoder model by combining encoder and decoder\n",
    "input_img = Input(shape=input_shape)\n",
    "encoded_img = encoder(input_img)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = Model(input_img, decoded_img)\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer=Adam(lr=0.001), loss=MeanSquaredError(),metrics=['accuracy'])\n",
    "\n",
    "# Display the summary of the autoencoder model\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the autoencoder model on block 1\n",
    "autoencoder.fit(x_block1_train, x_block1_train,\n",
    "                epochs=15,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_block1_test, x_block1_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_ELJ5mCKnuB"
   },
   "source": [
    "Saving the Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SK7TxC3KcY1",
    "outputId": "d5cbb786-13bd-45ad-e870-d4e3628eadef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-f82eb3ac1945>:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(autoencoder,'autoencoder_model.h5')\n"
     ]
    }
   ],
   "source": [
    "save_model(autoencoder,'autoencoder_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzhVTOoZECJa"
   },
   "source": [
    "# Transfer Learning : Block 2 Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIRSnwiZBnUI"
   },
   "source": [
    "1) Input Layer: The input layer is defined with the shape of (32,32,3).\n",
    "\n",
    "2) Encoder Part of AutoEncoder: The part of an existing auto-encoder model is extracted and the each layer is applied sequentially to the input layer (input_layer). The output of this process is then stored in encoder_output.\n",
    "\n",
    "3) CNN Model: Similarly the CNN model is extarcted and each layer is applied sequentially to the input layer (input_layer). The output of this process is then stored in cnn_output.\n",
    "\n",
    "4) The output from the encoder (encoder_output) is flattened using the Flatten layer to convert the 3D feature maps into a 1D vector.\n",
    "\n",
    "5) Concatinating the outputs of Encoder and CNN: the outputs from the Encoder and the CNN are concatenated.\n",
    "\n",
    "6) Fully connected layers: The concatinaated output are passed to the fully connected Dense layer with 256 neurons and ReLU activation function. A dropout rate of 0.5 was applied along with the dropout regularization to prevent overfitting.\n",
    "\n",
    "7) Output layer: the output is pased to an output Dense layer with 100 neurons where softmax activation function was used.\n",
    "\n",
    "8) Creating the transfer learning model: a transfer_model is created using the Model class from Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d123J5SdUyTY",
    "outputId": "867fbd6a-e470-4590-95c4-31d492bbec5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_64 (InputLayer)       [(None, 32, 32, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)          (None, 30, 30, 64)           1792      ['input_64[0][0]']            \n",
      "                                                                                                  \n",
      " model_44 (Functional)       (None, 8, 8, 32)             20640     ['input_64[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)          multiple                     73856     ['conv2d_87[11][0]']          \n",
      "                                                                                                  \n",
      " model_45 (Functional)       (None, 32, 32, 3)            29859     ['model_44[16][0]']           \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)          multiple                     295168    ['conv2d_88[11][0]']          \n",
      "                                                                                                  \n",
      " flatten_16 (Flatten)        (None, 3072)                 0         ['model_45[16][0]']           \n",
      "                                                                                                  \n",
      " flatten_17 (Flatten)        (None, 173056)               0         ['conv2d_89[11][0]']          \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 176128)               0         ['flatten_16[0][0]',          \n",
      " )                                                                   'flatten_17[0][0]']          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 256)                  4508902   ['concatenate_7[0][0]']       \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 256)                  0         ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 100)                  25700     ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45536039 (173.71 MB)\n",
      "Trainable params: 45535655 (173.70 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, Add, Concatenate, Input\n",
    "\n",
    "# Define input layer\n",
    "input_layer = Input(shape=(32, 32, 3))\n",
    "\n",
    "# Encoder part of the autoencoder\n",
    "encoder_output = input_layer\n",
    "for i in range(1, len(autoencoder.layers)):  # Iterate over all layers of the autoencoder\n",
    "    encoder_output = autoencoder.layers[i](encoder_output)\n",
    "\n",
    "# Filter only the layers from the CNN model\n",
    "cnn_layers = [layer for layer in model.layers if isinstance(layer, Conv2D)]\n",
    "\n",
    "# CNN model\n",
    "cnn_output = input_layer  # Start with the input layer for CNN\n",
    "for layer in cnn_layers:  # Iterate over CNN layers\n",
    "    cnn_output = layer(cnn_output)\n",
    "\n",
    "# Flatten the output from the encoder\n",
    "encoder_flattened = Flatten()(encoder_output)\n",
    "\n",
    "# Flatten the output from the CNN\n",
    "cnn_flattened = Flatten()(cnn_output)\n",
    "\n",
    "# Concatenate the outputs of the encoder and CNN\n",
    "combined_output = Concatenate()([encoder_flattened, cnn_flattened])\n",
    "\n",
    "# Fully connected layers\n",
    "combined_output = Dense(256, activation='relu')(combined_output)\n",
    "combined_output = Dropout(0.5)(combined_output)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(100, activation='softmax')(combined_output)\n",
    "\n",
    "# Create the transfer learning model\n",
    "transfer_model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Compile the transfer learning model\n",
    "transfer_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0X72rhAqaLIB",
    "outputId": "2b69836e-1689-47fe-dd43-cd1f6d50cd25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 254s 406ms/step - loss: 3.6690 - accuracy: 0.1048 - val_loss: 3.0921 - val_accuracy: 0.1992 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 247s 395ms/step - loss: 3.1836 - accuracy: 0.1769 - val_loss: 2.9012 - val_accuracy: 0.2424 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 258s 413ms/step - loss: 2.9235 - accuracy: 0.2398 - val_loss: 2.9480 - val_accuracy: 0.2460 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 282s 451ms/step - loss: 2.6486 - accuracy: 0.3000 - val_loss: 2.3734 - val_accuracy: 0.3694 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 301s 481ms/step - loss: 2.3981 - accuracy: 0.3647 - val_loss: 2.3033 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 291s 465ms/step - loss: 2.1668 - accuracy: 0.4129 - val_loss: 2.1796 - val_accuracy: 0.4148 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 268s 429ms/step - loss: 1.9714 - accuracy: 0.4645 - val_loss: 2.1767 - val_accuracy: 0.4400 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 281s 449ms/step - loss: 1.7655 - accuracy: 0.5146 - val_loss: 2.1567 - val_accuracy: 0.4434 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 252s 403ms/step - loss: 1.5821 - accuracy: 0.5640 - val_loss: 2.0572 - val_accuracy: 0.4756 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 267s 428ms/step - loss: 1.4064 - accuracy: 0.6076 - val_loss: 2.2784 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 279s 446ms/step - loss: 1.2604 - accuracy: 0.6437 - val_loss: 2.0492 - val_accuracy: 0.4910 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 284s 455ms/step - loss: 1.1222 - accuracy: 0.6835 - val_loss: 2.4105 - val_accuracy: 0.4680 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 247s 396ms/step - loss: 0.9920 - accuracy: 0.7187 - val_loss: 2.3290 - val_accuracy: 0.4728 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 262s 420ms/step - loss: 0.8785 - accuracy: 0.7487 - val_loss: 2.2702 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 239s 382ms/step - loss: 0.5626 - accuracy: 0.8387 - val_loss: 2.1548 - val_accuracy: 0.5494 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 241s 385ms/step - loss: 0.4207 - accuracy: 0.8781 - val_loss: 2.3072 - val_accuracy: 0.5490 - lr: 2.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x796a28867e50>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_model.fit(x_block2_train, y_block2_train, epochs=50, validation_data=(x_block2_test, y_block2_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-667_hYoKtiB"
   },
   "source": [
    "Saving the transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqiEYQd0KtPV",
    "outputId": "6d8fab1b-975b-416d-cab5-578bf230c357"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-146-2a9a68f3f1db>:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(transfer_model,'transfer_model.h5')\n"
     ]
    }
   ],
   "source": [
    "save_model(transfer_model,'transfer_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8ac3cDE78Al"
   },
   "source": [
    "# Comparing the CNN model and Auto-Encoder Model on the Block 2 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuC2-5oUFW4d"
   },
   "source": [
    "The same CNN model is run on block2 dataset images to compare its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nJxTZn8JfQH",
    "outputId": "6fdd52fb-e594-4d2f-f7e9-3de8f34fb1de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "625/625 [==============================] - 206s 329ms/step - loss: 3.8236 - accuracy: 0.0979 - val_loss: 3.6912 - val_accuracy: 0.1182 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "625/625 [==============================] - 275s 441ms/step - loss: 3.2147 - accuracy: 0.1603 - val_loss: 3.2045 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "625/625 [==============================] - 214s 342ms/step - loss: 3.0131 - accuracy: 0.1953 - val_loss: 3.1408 - val_accuracy: 0.1788 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "625/625 [==============================] - 231s 369ms/step - loss: 2.8456 - accuracy: 0.2301 - val_loss: 2.5083 - val_accuracy: 0.3136 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "625/625 [==============================] - 217s 346ms/step - loss: 2.7078 - accuracy: 0.2585 - val_loss: 2.5966 - val_accuracy: 0.3026 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "625/625 [==============================] - 210s 336ms/step - loss: 2.5596 - accuracy: 0.2869 - val_loss: 2.3082 - val_accuracy: 0.3686 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "625/625 [==============================] - 210s 336ms/step - loss: 2.4345 - accuracy: 0.3154 - val_loss: 2.2871 - val_accuracy: 0.3764 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "625/625 [==============================] - 218s 349ms/step - loss: 2.2841 - accuracy: 0.3481 - val_loss: 2.2368 - val_accuracy: 0.3748 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "625/625 [==============================] - 217s 347ms/step - loss: 2.1551 - accuracy: 0.3780 - val_loss: 2.2359 - val_accuracy: 0.3980 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "625/625 [==============================] - 237s 379ms/step - loss: 1.9879 - accuracy: 0.4203 - val_loss: 2.1284 - val_accuracy: 0.4286 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "625/625 [==============================] - 217s 348ms/step - loss: 1.8647 - accuracy: 0.4539 - val_loss: 2.0761 - val_accuracy: 0.4442 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "625/625 [==============================] - 214s 343ms/step - loss: 1.7597 - accuracy: 0.4775 - val_loss: 2.1053 - val_accuracy: 0.4386 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "625/625 [==============================] - 243s 388ms/step - loss: 1.6558 - accuracy: 0.5041 - val_loss: 2.1902 - val_accuracy: 0.4318 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "625/625 [==============================] - 218s 349ms/step - loss: 1.5300 - accuracy: 0.5368 - val_loss: 2.2834 - val_accuracy: 0.4606 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "625/625 [==============================] - 216s 346ms/step - loss: 1.2234 - accuracy: 0.6140 - val_loss: 1.8795 - val_accuracy: 0.5212 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "625/625 [==============================] - 231s 370ms/step - loss: 1.0842 - accuracy: 0.6488 - val_loss: 1.9358 - val_accuracy: 0.5294 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "625/625 [==============================] - 228s 365ms/step - loss: 0.9930 - accuracy: 0.6744 - val_loss: 1.9332 - val_accuracy: 0.5352 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "625/625 [==============================] - 236s 377ms/step - loss: 0.9150 - accuracy: 0.7037 - val_loss: 1.9457 - val_accuracy: 0.5400 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "625/625 [==============================] - 206s 330ms/step - loss: 0.8463 - accuracy: 0.7147 - val_loss: 1.9717 - val_accuracy: 0.5448 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "625/625 [==============================] - 214s 342ms/step - loss: 0.8129 - accuracy: 0.7304 - val_loss: 2.0028 - val_accuracy: 0.5390 - lr: 4.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x796a1ef7cbe0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN Model\n",
    "model_on_block2 = model\n",
    "model_on_block2.fit(x_block2_train,y_block2_train,epochs=40,validation_data=(x_block2_test,y_block2_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAGXJugsF6yV"
   },
   "source": [
    "Similary the autoencoder model is tested on block 2 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkVH6fEe8Tnq",
    "outputId": "dea352fc-4e20-4a95-981d-f13eef366ade"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "125/125 [==============================] - 127s 1s/step - loss: 19946.5723 - accuracy: 0.5040 - val_loss: 19944.9102 - val_accuracy: 0.4518\n",
      "Epoch 2/15\n",
      "125/125 [==============================] - 119s 955ms/step - loss: 19931.2441 - accuracy: 0.5506 - val_loss: 19973.0352 - val_accuracy: 0.4756\n",
      "Epoch 3/15\n",
      "125/125 [==============================] - 123s 989ms/step - loss: 19930.4336 - accuracy: 0.5436 - val_loss: 19944.5488 - val_accuracy: 0.5494\n",
      "Epoch 4/15\n",
      "125/125 [==============================] - 117s 936ms/step - loss: 19930.3008 - accuracy: 0.5208 - val_loss: 19944.3047 - val_accuracy: 0.5382\n",
      "Epoch 5/15\n",
      "125/125 [==============================] - 112s 897ms/step - loss: 19930.2891 - accuracy: 0.5180 - val_loss: 19973.3457 - val_accuracy: 0.4328\n",
      "Epoch 6/15\n",
      "125/125 [==============================] - 123s 981ms/step - loss: 19930.1895 - accuracy: 0.4802 - val_loss: 19944.2402 - val_accuracy: 0.4343\n",
      "Epoch 7/15\n",
      "125/125 [==============================] - 116s 930ms/step - loss: 19930.1289 - accuracy: 0.5101 - val_loss: 19944.2285 - val_accuracy: 0.5289\n",
      "Epoch 8/15\n",
      "125/125 [==============================] - 116s 926ms/step - loss: 19930.1172 - accuracy: 0.5187 - val_loss: 19944.2266 - val_accuracy: 0.5306\n",
      "Epoch 9/15\n",
      "125/125 [==============================] - 117s 938ms/step - loss: 19930.1660 - accuracy: 0.5007 - val_loss: 19944.2285 - val_accuracy: 0.5316\n",
      "Epoch 10/15\n",
      "125/125 [==============================] - 117s 937ms/step - loss: 19930.1230 - accuracy: 0.5174 - val_loss: 19944.2305 - val_accuracy: 0.5370\n",
      "Epoch 11/15\n",
      "125/125 [==============================] - 113s 902ms/step - loss: 19930.1133 - accuracy: 0.5209 - val_loss: 19944.2324 - val_accuracy: 0.5353\n",
      "Epoch 12/15\n",
      "125/125 [==============================] - 117s 934ms/step - loss: 19930.1035 - accuracy: 0.5133 - val_loss: 19944.2227 - val_accuracy: 0.5013\n",
      "Epoch 13/15\n",
      "125/125 [==============================] - 116s 930ms/step - loss: 19930.1055 - accuracy: 0.5086 - val_loss: 19944.2207 - val_accuracy: 0.5119\n",
      "Epoch 14/15\n",
      "125/125 [==============================] - 116s 931ms/step - loss: 19930.1094 - accuracy: 0.5046 - val_loss: 19944.2207 - val_accuracy: 0.5019\n",
      "Epoch 15/15\n",
      "125/125 [==============================] - 118s 942ms/step - loss: 19930.1035 - accuracy: 0.5008 - val_loss: 19944.2207 - val_accuracy: 0.5028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x79d014e023e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the AutoEncoder Model on block2 images dataset\n",
    "auto_encoder_model_on_block2 = autoencoder\n",
    "auto_encoder_model_on_block2.fit(x_block2_train, x_block2_train,\n",
    "                epochs=15,\n",
    "                batch_size=128,\n",
    "                validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
